{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9c90f7-c6ef-4e45-8fde-2224a1d212fc",
   "metadata": {},
   "source": [
    "## 기본적인 Prompt 구조 이해\n",
    "prompt에는 3가지 종류의 역할(role)이 존재\n",
    "1. system prompt: 사용자 prompt를 입력받기 이전에 정의되는 전제 및 규칙\n",
    "2. user prompt: 사용자가 LLM에게 실제로 요청하는 prompt\n",
    "3. assistant prompt: LLM이 응답하는 prompt\n",
    "\n",
    "#### system prompt란?\n",
    "User prompt를 LLM에게 전달하기 전 관련된 맥락이나 응답지침 등을 설정하는 prompt\n",
    "- 출력 형태 지정(ex.JSON, 딕셔너리 등)\n",
    "- 페르소나(투자 전문가, 예술가 등) 및 어조 설정(공손한, 전문적인 등)\n",
    "- 모델이 지켜야할 규칙들 설정\n",
    "- 기타 base가 되는 외부 정보 및 지식 주입\n",
    "\n",
    "#### ChatGPT를 포함한 웬만한 LLM 모델 서비스들은 prompt 입력시 기본적으로 저장된 system prompt가 내부에서 동작하고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38f3e9b-dc55-4995-9e23-a00f108335c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194eabeb-35de-4295-b977-84fd30e2801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_API_KEY=getpass('OpenAI API key:')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac188e41-52df-4416-a8e9-86a39e680b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=OpenAI(api_key=MY_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8820c1e1-6987-4a74-8cfa-9fd189f1d51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘은 왜 하늘색인지 궁금하시군요! 하늘은 빛이라는 것이 있어요. 태양에서 나오는 빛은 다양한 색깔을 가지고 있는데, 그 중에서 파란색 빛이 하늘에 가장 많이 퍼져요. 그래서 우리 눈에 보이는 하늘은 파란색으로 보이게 되는 거에요. 이렇게 파란색 빛이 하늘에 반사되면서 우리가 보는 것이에요. 그래서 하늘은 파란색으로 보이는 거죠!\n"
     ]
    }
   ],
   "source": [
    "completion=client.chat.completions.create(model ='gpt-3.5-turbo', \n",
    "                                          messages=[{'role':'system',\n",
    "                                                     'content': '당신은 물리학 선생님입니다. 초등학생에게 설명하듯 아주 쉽고 친근하게 설명해야합니다.'},\n",
    "                                                    {'role':'user', 'content': '왜 하늘은 하늘색인가요?'}],\n",
    "                                            temperature=0)\n",
    "print(completion.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f2b462-cfb1-4d15-88b5-901784972d1c",
   "metadata": {},
   "source": [
    "- 텍스트가 짧다면 user pormpt에 system prompt 내용을 같이 작성해도 무방함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bcbc95-c7d3-4679-a7ca-d55991d3f21b",
   "metadata": {},
   "source": [
    "### Stream 객체 살펴보기\n",
    "- stream =True로 저장시 GPT가 문장을 모두 완성하기 전에 각 토큰별로 완성되는대로 바로바로 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f76d00-3b03-41b7-85ed-05d62ca94f32",
   "metadata": {},
   "source": [
    "#stream=True로 설정하게 되면 응답객체가 ChatCompletion이 아니라 ChatCompletionChunk로 반환됨\n",
    " #Chunk는 토큰들의 의미있는 집합\n",
    "completion_stream = client.chat.completions.create(model ='gpt-3.5-turbo', \n",
    "                                          messages=[{'role':'user', 'content': '왜 하늘은 하늘색인가요?'}],\n",
    "                                            temperature=0,\n",
    "                                                stream=True)\n",
    "for i in completion_stream:\n",
    "    #print(i)\n",
    "    content=i.choices[0].delta.content\n",
    "    \n",
    "    #content의 값이 비어있지 않은경우\n",
    "    if content is not None: \n",
    "        print(content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a8d19-0e66-4114-afbc-f63f50e701f8",
   "metadata": {},
   "source": [
    "### LLM의 task에 따른 평가지표들을 알아보고 대화 및 Q&A task 에 실제로 적용해보자\n",
    "#### 전통적인 Language Model 평가지표\n",
    "1.MMLU(Massive Multitask Language Understanding)\n",
    "- 다양한 분야에 대한 질문 후 정답을 찾아내게 하는 객관식 시험\n",
    "\n",
    "2.HellaSwag\n",
    "- 문장들을 주고 이어지는 마지막 문장으로 가장 적합한 문장들 4개중 하나를 고르는 시험"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a67c090-59d2-4c67-acf9-d7ea0093b559",
   "metadata": {},
   "source": [
    "#### 위 평가 지표들은 범용 Language Model에 대한 평가 방법론들이라 현재 우리가 진행할 대화 및 Q&A에서는 적합하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2a9ecb-f067-49f9-9b9f-e166e55b90de",
   "metadata": {},
   "source": [
    "### 대화 및 Q&A task 에 적합한 평가 방식\n",
    "1. **Human Based Evaluation** - 사람이 직접 평가하는 방법\n",
    "2. **Model Based Evaluation** -  LLM이 평가하는 방법\n",
    "3. **Code Based Evaltuation** - 코드로 평가하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f373484a-bab1-4aa4-84f1-8eb5b9f41dbf",
   "metadata": {},
   "source": [
    "### 1) Human Based Evaluation\n",
    "- 전문가 블라인드 A/B테스트(각기 다른 LLM의 2가지 답변 중 더 좋은 답변을 사람이 선택)\n",
    "- 명확한 결과로 성능을 판단하기 쉬움\n",
    "- 많은 인력에 따른 비용과 시간이 필요함\n",
    "\n",
    "LMSys사 Chatbot Arena 평가방법\n",
    "- 대표적인 Human Based 방식으로 동일한 질문에 대해 2개의 모델의 답변을 보고 승/패/무 투표 이후 모델명을 공개하는 방식\n",
    "- 사이트: https://chat.lmsys.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4467b-0360-4d34-8971-9c4723ab3835",
   "metadata": {},
   "source": [
    "#### 2) Model Based Evaluation\n",
    "고성능 LLM(GPT-4o이상)을 통해 평가하는 방법\n",
    "-실제로 사람이 평가하는 것과 굉장히 유사하다는 논문 결과들이 나오고 있음\n",
    "\n",
    "평가하는 방식\n",
    "1. **Pairwise Comparison**\n",
    "- 2개의 평가받을 모델에 같은 질문을 하고, 고성능 모델이 2개의 답변을 받아 둘 중 어떤 답변이 더 좋은지 또는 무승부인지를 출력\n",
    "2. **Single Answer Grading**\n",
    "- 질문과 답변이 있을 때 모델이 답변에 점수를 매기는 것\n",
    "3. **Reference - Guided Grading**\n",
    "- 예시답변을 주고 이와 비교하여 +,-로 상대적인 점수를 매기는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59d690-307c-4e6a-9897-a4f1c6f8ee07",
   "metadata": {},
   "source": [
    "### 3) Code Based Evaluation\n",
    "우리에게 익숙한 코드/로직을 통한 평가 방법\n",
    "- Accuracy, Precision, Recall, F1-Score\n",
    "- ROUGE (Recall-Oriented Understudy for Gisting Evaluation): 자연어 생성 및 요약을 평가\n",
    "- BLEU(Billingual Evaluation Understudy): 번역, 요약, 자연어 생성 등을 평가\n",
    "\n",
    "단 Human Based 및 Model Based에 비해 실제 사용자들의 만족과는 다소 거리가 있을 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a5756-ffad-4e92-a726-f66714293a3f",
   "metadata": {},
   "source": [
    "### 최신논문을 참조하여 대화 및 Q&A task에 적합한 평가 방법에 대한 힌트를 얻어보자\n",
    "- 논문명: Judging LLM as-a-Judge with MT-Bench and Chatbot Arena\n",
    "- GPT-4로 평가 진행(그때 당시 가장 성능이 좋은 LLM)\n",
    "- 해당 논문의 핵심은 LLM의 평가 결과와 사람의 평가 결과의 일치율이 점점 높아지고 있다는 것\n",
    "- 이는 기계의 판단이 인간의 판단에 도움이 되며, 기계를 통한 자동화된 평가 프로세스 개발이 가능하다는 것을 시사함\n",
    "- 실제로 해당 논문에서 인간의 75%가 기계의 판단이 합리적이라 생각했고, 34%가 자신의 선택을 바꿀 의향이 있다고 응답함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcafe8c-c488-4f90-9d0c-b7af1afec7c8",
   "metadata": {},
   "source": [
    "### benchmark: 다양한 시스템, 모델, 소프트웨어 등을 평가하고 비교하기 위해 사용되는 표준 테스트 세트 또는 기준\n",
    "\n",
    "### MT-bench(Multi-turn bench) \n",
    "- multi-turn(이어지는 대화) 능력을 평가하는 벤치마크\n",
    "- 먼저 58명의 전문가가 모델의 응답을 평가하고 LLM을 심판으로 사용하여 사람의 평가와 일치하는지 검증하는 방식\n",
    "- **Multi-turn 대화**: MT-bench에는 8개 카테고리(작문, 역할놀이, 추출, 추론, 수학, 코딩, 지식1(물리/수학), 지식2(인문/사회)의 80개의 고품질 질문으로 구성되어있고, 각 질문은 여러차례의 응답을 요구하여 모델의 대화 지속능력을 평가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc601342-c143-4048-b406-1ac05ce0e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = ' 하늘은 왜 하늘색인가요?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63aeca2f-794a-42b8-8e63-c9be43e7f5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘은 일반적으로 푸른 색을 띠는데, 이는 태양 빛이 대기 중의 공기 분자들과 상호 작용하여 발생하는 현상 때문입니다. 태양 빛은 다양한 파장을 가지고 있는데, 그 중에서도 파란색과 녹색의 파장이 대기 분자들과 가장 많이 상호 작용하여 산란되기 때문에 우리가 보는 하늘은 주로 푸른 색을 띠게 됩니다. 이러한 현상을 산란이라고 하는데, 이는 태양 빛이 대기 분자들과 부딪히면서 다양한 방향으로 흩어지는 현상을 말합니다. 따라서 하늘은 푸른 색을 띄는 것이지만, 일출이나 일몰 시에는 태양 빛이 대기를 통과하면서 붉은 색을 띠게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "#gpt-3.5-turbo\n",
    "completion = client.chat.completions. create(model='gpt-3.5-turbo',\n",
    "                                             messages=[{'role':'user', 'content':question}],\n",
    "                                             temperature=0\n",
    "                                            )\n",
    "\n",
    "answer_a=completion.choices[0].message.content\n",
    "print(answer_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "540b0491-aec2-45fe-b63b-80a246852c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘의 색깔이 왜 하늘색인지 설명하기 위해서는 빛의 산란 현상을 이해해야 합니다. 태양에서 나오는 빛은 여러 가지 색의 빛으로 구성된 흰색 빛입니다. 이 빛이 지구 대기에 도달하면, 대기 분자와 작은 입자들에 의해 산란되는데, 이 과정을 '레일리 산란'이라고 합니다.\n",
      "\n",
      "레일리 산란은 파장이 짧은 빛 (예: 파란색과 보라색)이 파장이 긴 빛 (예: 빨간색과 노란색)보다 더 많이 산란되는 현상입니다. 파란색 빛의 파장은 매우 짧기 때문에 대기 중의 분자들에 의해 쉽게 산란되고, 이로 인해 우리가 하늘을 보았을 때 파란색으로 보이게 됩니다.\n",
      "\n",
      "그러나 해가 지평선에 가까울 때, 즉 일출이나 일몰 때는 하늘이 빨갛게 보이는 경우가 많습니다. 이는 태양 빛이 대기를 통과하는 거리가 길어지면서 파란색 빛이 더 많이 산란되고, 상대적으로 파장이 긴 빨간색 빛이 덜 산란되어 우리 눈에 도달하기 때문입니다. 이러한 현상을 '레일리 산란'의 결과로 설명할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "#gpt-4-turbo\n",
    "completion = client.chat.completions. create(model='gpt-4-turbo',\n",
    "                                             messages=[{'role':'user', 'content':question}],\n",
    "                                             temperature=0\n",
    "                                            )\n",
    "\n",
    "answer_b=completion.choices[0].message.content\n",
    "print(answer_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3629500b-3da4-4015-a698-08d41759d86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[System]\n",
      "Please act as an impartial judge and evaluate the quality of the responses provided by two\n",
      "AI assistants to the user question displayed below. You should choose the assistant that\n",
      "follows the user’s instructions and answers the user’s question better. Your evaluation\n",
      "should consider factors such as the helpfulness, relevance, accuracy, depth, creativity,\n",
      "and level of detail of their responses. Begin your evaluation by comparing the two\n",
      "responses and provide a short explanation. Avoid any position biases and ensure that the\n",
      "order in which the responses were presented does not influence your decision. Do not allow\n",
      "the length of the responses to influence your evaluation. Do not favor certain names of\n",
      "the assistants. Be as objective as possible. After providing your explanation, output your\n",
      "final verdict by strictly following this format: \"[[A]]\" if assistant A is better, \"[[B]]\"\n",
      "if assistant B is better, and \"[[C]]\" for a tie.\n",
      "[User Question]\n",
      " 하늘은 왜 하늘색인가요?\n",
      "[The Start of Assistant A’s Answer]\n",
      "하늘은 파란색으로 보이는데, 이는 태양 빛이 대기 중의 공기 분자들과 상호 작용하여 발생하는 현상입니다. 태양 빛은 다양한 색상의 빛으로 구성되어 있지만, 대기 중의 공기 분자들은 파란색 빛을 더 많이 흡수하고 다른 색상의 빛을 덜 흡수합니다. 그래서 우리 눈에는 파란색 빛이 더 많이 반사되어 보이게 되는 것이죠. 이러한 이유로 하늘은 파란색으로 보이게 되는 것입니다.\n",
      "[The End of Assistant A’s Answer]\n",
      "[The Start of Assistant B’s Answer]\n",
      "하늘의 색깔이 왜 하늘색인지 설명하기 위해서는 빛의 산란 현상을 이해해야 합니다. 태양에서 나오는 빛은 여러 가지 색의 빛으로 구성된 흰색 빛입니다. 이 빛이 지구 대기에 도달하면, 대기 분자와 작은 입자들에 의해 산란되는데, 이 과정을 '레일리 산란'이라고 합니다.\n",
      "\n",
      "레일리 산란은 파장이 짧은 빛 (예: 파란색과 보라색)이 파장이 긴 빛 (예: 빨간색과 노란색)보다 더 많이 산란되는 현상입니다. 파란색 빛의 파장은 매우 짧기 때문에 대기 중의 분자들에 의해 쉽게 산란되고, 이로 인해 우리가 하늘을 보았을 때 파란색으로 보이게 됩니다.\n",
      "\n",
      "그러나 해가 지평선에 가까울 때, 즉 일출이나 일몰 때는 하늘이 빨갛게 보이는 경우가 많습니다. 이는 태양 빛이 대기를 통과하는 거리가 길어지면서 파란색 빛이 더 많이 산란되고, 상대적으로 파장이 긴 빨간색 빛이 덜 산란되어 우리 눈에 도달하기 때문입니다. 이러한 현상을 '레일리 산란'의 결과로 설명할 수 있습니다.\n",
      "[The End of Assistant B’s Answer]\n"
     ]
    }
   ],
   "source": [
    "#논문 프롬프트 참조\n",
    "prompt = f\"\"\"[System]\n",
    "Please act as an impartial judge and evaluate the quality of the responses provided by two\n",
    "AI assistants to the user question displayed below. You should choose the assistant that\n",
    "follows the user’s instructions and answers the user’s question better. Your evaluation\n",
    "should consider factors such as the helpfulness, relevance, accuracy, depth, creativity,\n",
    "and level of detail of their responses. Begin your evaluation by comparing the two\n",
    "responses and provide a short explanation. Avoid any position biases and ensure that the\n",
    "order in which the responses were presented does not influence your decision. Do not allow\n",
    "the length of the responses to influence your evaluation. Do not favor certain names of\n",
    "the assistants. Be as objective as possible. After providing your explanation, output your\n",
    "final verdict by strictly following this format: \"[[A]]\" if assistant A is better, \"[[B]]\"\n",
    "if assistant B is better, and \"[[C]]\" for a tie.\n",
    "[User Question]\n",
    "{question}\n",
    "[The Start of Assistant A’s Answer]\n",
    "{answer_a}\n",
    "[The End of Assistant A’s Answer]\n",
    "[The Start of Assistant B’s Answer]\n",
    "{answer_b}\n",
    "[The End of Assistant B’s Answer]\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51b6ece7-a8a1-4f61-9e19-9d35938c2347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both Assistant A and Assistant B provide explanations for why the sky appears blue, but there are differences in the depth and detail of their responses.\n",
      "\n",
      "Assistant A gives a basic explanation, mentioning that the sky appears blue due to the interaction of sunlight with air molecules, which absorb more blue light and reflect it to our eyes. However, the explanation lacks specific scientific terminology and does not delve into the underlying physical principles.\n",
      "\n",
      "Assistant B, on the other hand, provides a more detailed and scientifically accurate explanation. It introduces the concept of Rayleigh scattering, explaining that shorter wavelengths (like blue and violet) are scattered more than longer wavelengths (like red and yellow). Assistant B also includes additional information about why the sky can appear red during sunrise and sunset, providing a more comprehensive understanding of the phenomenon.\n",
      "\n",
      "Overall, Assistant B's response is more informative, accurate, and detailed, making it the better answer to the user's question.\n",
      "\n",
      "[[B]]\n"
     ]
    }
   ],
   "source": [
    "#가장 최신 gpt-4o 모델로 앞선 두 모델의 응답을 평가\n",
    "completion = client.chat.completions.create(model='gpt-4o',\n",
    "                                             messages=[{'role':'user', 'content':prompt}],\n",
    "                                             temperature=0\n",
    "                                            )\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f460d-95a1-4971-b382-cf1feae0fb28",
   "metadata": {},
   "source": [
    "### 장단점 비교\n",
    "1. Human Based Evaluation\n",
    "- 통제된 환경을 가정했을 때 사람이 직접 평가한 방법이라 안정적이고 신뢰할 수 있음\n",
    "- 전문가가 아닌 불특정 다수의 경우 약간의 노이즈가 발생할 수 있음\n",
    "- 전문가가 아닌 경우 평가 정확도 저하 및 속도가 더 오래 걸릴 수 있음\n",
    "\n",
    "2. Model Based Evaluation\n",
    "- 사람 평가와 어느정도 유사한 수준의 평가를 내릴 수 있음\n",
    "- 평가를 위해 API 호출이 필요한데 평가 데이터가 굉장히 많을 경우 수백만원 이상은 금방 넘어갈 수 있음\n",
    "\n",
    "3. Code Based Evaluation\n",
    "- 위 방법들에 비해 인력 비용, 모델호출 비용등이 없는 무료 평가 방법\n",
    "- task에 따라 활용할 수 있는 범위가 제한적\n",
    "- 사람에게 적합한 답변을 선택하는데 있어서는 신뢰도가 상대적으로 떨어지는 편"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd1067-e778-4e9f-a19c-9aa2d7033c6b",
   "metadata": {},
   "source": [
    "### 프롬프트 엔지니어링 고급 기법 적용\n",
    "1. **few-shot**\n",
    "- 참고할 수 있는 문제-정답 예시나 사례들을 프롬프트에 추가하여 질의\n",
    "- 논문: https://arxiv.org/abs/2005.14165\n",
    "\n",
    "2. **Chain-of-thought**\n",
    "- few-shot에 추가로 문제 해결과정을 단계별로 모델에게 알려주면서 질의\n",
    "- 논문: https://arxiv.org/abs/2201.11903"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f2b8a8-b0af-4dbf-a001-8b80b8370db3",
   "metadata": {},
   "source": [
    "### Zero-shot\n",
    "- 질의에 아무런 예시가 없는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f571877-fd13-4c37-acb5-a69c2a8c9750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J.K. Rowling wrote the Harry Potter book series.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''Q: Who wrote the book 'harry potter'?'''\n",
    "completion = client.chat.completions. create(model='gpt-3.5-turbo',\n",
    "                                             messages=[{'role':'user', 'content':prompt}],\n",
    "                                             temperature=0\n",
    "                                            )\n",
    "\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166bf0fa-0ce1-4149-b71f-318b7171d291",
   "metadata": {},
   "source": [
    "### Few-shot\n",
    "- Few-shot(one-shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4a47ed9-9b20-430c-892d-53143de98355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Who wrote the book 'Harry Potter'?\n",
      "A: J.K. Rowling.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''Answer these question:\n",
    "Q: Who wrote the book 'harry potter'?\n",
    "\n",
    "Below is an example for your reference.\n",
    "Q: Who sang 'One call away'\n",
    "A: Charlie Puth.\n",
    "'''\n",
    "completion = client.chat.completions. create(model='gpt-3.5-turbo',\n",
    "                                             messages=[{'role':'user', 'content':prompt}],\n",
    "                                             temperature=0\n",
    "                                            )\n",
    "\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "#예시를 들어준 대답 형식대로 질문에 대해 사람이름만 대답하는 것을 볼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9308db3e-0319-4185-af16-6d9cd4b45e83",
   "metadata": {},
   "source": [
    "#### Chain of Thought \n",
    "- 마이크로소프트에서 사용한 예시 프롬프트 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9b7a4ef-2991-4c1c-95de-698d1d791e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice would have 5 apples. \n",
      "\n",
      "She started with 5 apples, threw 3 apples (5-3=2), gave 2 apples to Bob (2-2=0), and received 1 apple back from Bob (0+1=1).\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, \\n\n",
    "how many apples does Alice have?\"\"\"\n",
    "\n",
    "completion = client.chat.completions. create(model='gpt-3.5-turbo',\n",
    "                                             messages=[{'role':'user', 'content':prompt}],\n",
    "                                             temperature=0\n",
    "                                            )\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "\n",
    "#1개가 나와야하는데 잘못계산함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbbc574-95fb-48d6-9d71-3e8c38ab9408",
   "metadata": {},
   "source": [
    "### COT+One-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "813548f4-32a7-478d-8b47-e9c883c269f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice has 5 apples - 3 thrown = 2 apples\n",
      "2 apples - 2 given to Bob = 0 apples\n",
      "Bob gives 1 apple back to Alice\n",
      "0 apples + 1 apple = 1 apple\n",
      "\n",
      "Therefore, Alice has 1 apple.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, \\n\n",
    "how many apples does Alice have?\n",
    "\n",
    "\n",
    "    Below is an example for your reference.\n",
    "\n",
    "    Lisa has 7 apples, throws 1 apple, gives 4 apples to Bart and Bart gives one back.\n",
    "    7-1=6\n",
    "    6-4=2\n",
    "    2+1=3\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions. create(model='gpt-3.5-turbo',\n",
    "                                             messages=[{'role':'user', 'content':prompt}],\n",
    "                                             temperature=0\n",
    "                                            )\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d31d7-ead9-44d7-9a27-b2228ec5aca0",
   "metadata": {},
   "source": [
    "### 또다른 프롬프트 고도화 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8695f201-2615-4423-a7f8-0a963e955616",
   "metadata": {},
   "source": [
    "- KMMLU(Measuring Massive Multitask Language Inderstand in Korea)논문의 프롬프트 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0459cefd-95a8-4255-94e0-3d4431de338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 정답은 B=6\n",
    "question = 'x, y가 세 부등식 y ≤ x+3, y ≤ -4x+3, y ≥ 0을 만족할 때, x+y의 최댓값을 M, 최솟값을 m이라 하면 M-m의 값은?'\n",
    "A = 4\n",
    "B = 6\n",
    "C = 8\n",
    "D = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddc7ea1d-78dc-4199-8aed-2b58ac084e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 부등식들을 통해 영역을 구하고, 그 영역 내에서 \\(x+y\\)의 최댓값과 최솟값을 찾으면 됩니다.\n",
      "\n",
      "1. **부등식 정리:**\n",
      "   - \\(y \\leq x + 3\\)\n",
      "   - \\(y \\leq -4x + 3\\)\n",
      "   - \\(y \\geq 0\\)\n",
      "\n",
      "2. **교점 찾기:**\n",
      "   - \\(y = x + 3\\)와 \\(y = -4x + 3\\)의 교점을 찾습니다.\n",
      "     \\[\n",
      "     x + 3 = -4x + 3 \\implies 5x = 0 \\implies x = 0\n",
      "     \\]\n",
      "     \\(x = 0\\)일 때, \\(y = 3\\). 따라서 교점은 \\((0, 3)\\)입니다.\n",
      "\n",
      "3. **영역의 꼭짓점 찾기:**\n",
      "   - \\(y = x + 3\\)와 \\(y = 0\\)의 교점:\n",
      "     \\[\n",
      "     x + 3 = 0 \\implies x = -3\n",
      "     \\]\n",
      "     따라서 교점은 \\((-3, 0)\\)입니다.\n",
      "   - \\(y = -4x + 3\\)와 \\(y = 0\\)의 교점:\n",
      "     \\[\n",
      "     -4x + 3 = 0 \\implies x = \\frac{3}{4}\n",
      "     \\]\n",
      "     따라서 교점은 \\(\\left(\\frac{3}{4}, 0\\right)\\)입니다.\n",
      "\n",
      "4. **영역의 꼭짓점:**\n",
      "   - \\((-3, 0)\\)\n",
      "   - \\((0, 3)\\)\n",
      "   - \\(\\left(\\frac{3}{4}, 0\\right)\\)\n",
      "\n",
      "5. **\\(x+y\\)의 값 계산:**\n",
      "   - \\((-3, 0)\\)에서 \\(x+y = -3 + 0 = -3\\)\n",
      "   - \\((0, 3)\\)에서 \\(x+y = 0 + 3 = 3\\)\n",
      "   - \\(\\left(\\frac{3}{4}, 0\\right)\\)에서 \\(x+y = \\frac{3}{4} + 0 = \\frac{3}{4}\\)\n",
      "\n",
      "6. **최댓값과 최솟값:**\n",
      "   - 최댓값 \\(M = 3\\)\n",
      "   - 최솟값 \\(m = -3\\)\n",
      "\n",
      "7. **\\(M - m\\) 계산:**\n",
      "   \\[\n",
      "   M - m = 3 - (-3) = 6\n",
      "   \\]\n",
      "\n",
      "따라서, \\(M - m\\)의 값은 \\(\\boxed{6}\\)입니다. 정답은 B입니다.\n"
     ]
    }
   ],
   "source": [
    "prompt = f'''{question}\n",
    "A. {A}\n",
    "B. {B}\n",
    "C. {C}\n",
    "D. {D}\n",
    "정답:\n",
    "'''\n",
    "completion = client.chat.completions. create(model='gpt-4o',\n",
    "                                             messages=[{'role':'user', 'content':prompt}],\n",
    "                                             temperature=0\n",
    "                                            )\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c5f2405-7d26-4e21-a241-94da9b9dbf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C. 8\n",
      "\n",
      "부등식을 그래프로 그려보면, 세 부등식이 만족하는 영역은 삼각형 모양이 됩니다. 이 삼각형의 꼭지점은 (0,0), (1,2), (3,0)입니다.\n",
      "\n",
      "따라서 x+y의 최댓값은 (3,0)일 때이고, 최솟값은 (0,0)일 때입니다. 따라서 M-m = 3-0 = 3이므로, 8이 됩니다.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions. create(model='gpt-3.5-turbo',\n",
    "                                             messages=[{'role':'user', 'content':prompt}],\n",
    "                                             temperature=0\n",
    "                                            )\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "#낮은 모델은 정답 틀림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee69ea-c62b-441b-8190-025df54a9f12",
   "metadata": {},
   "source": [
    "### GPT 3.5 모델로 고도화 시켜보자\n",
    "- 페르소나 적용\n",
    "- 영문 prompt 작성\n",
    "- 효과적인 prompt 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6689cd2a-049e-442f-b4d8-b5aeaba20ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C. 8\n",
      "\n",
      "To find the maximum and minimum values of x+y, we need to find the intersection points of the three inequalities.\n",
      "\n",
      "First, we find the intersection points of y ≤ x+3 and y ≤ -4x+3:\n",
      "x+3 = -4x+3\n",
      "5x = 0\n",
      "x = 0\n",
      "\n",
      "Plugging x = 0 into y ≤ x+3, we get y ≤ 3. So the intersection point is (0, 3).\n",
      "\n",
      "Next, we find the intersection points of y ≤ x+3 and y ≥ 0:\n",
      "y = x+3\n",
      "y = 0\n",
      "\n",
      "Plugging y = 0 into y = x+3, we get x = -3. So the intersection point is (-3, 0).\n",
      "\n",
      "Finally, we find the intersection points of y ≤ -4x+3 and y ≥ 0:\n",
      "y = -4x+3\n",
      "y = 0\n",
      "\n",
      "Plugging y = 0 into y = -4x+3, we get x = 3/4. So the intersection point is (3/4, 0).\n",
      "\n",
      "Now we evaluate x+y at the intersection points:\n",
      "(0, 3): x+y = 0+3 = 3\n",
      "(-3, 0): x+y = -3+0 = -3\n",
      "(3/4, 0): x+y = 3/4+0 = 3/4\n",
      "\n",
      "Therefore, the maximum value of x+y is 3 and the minimum value is -3. So M-m = 3-(-3) = 6.\n"
     ]
    }
   ],
   "source": [
    "#페르소나 부여\n",
    "prompt = f'''You are an professional in mathematics. \n",
    "Below is given a math question in Korea.\n",
    "\n",
    "{question}\n",
    "A. {A}\n",
    "B. {B}\n",
    "C. {C}\n",
    "D. {D}\n",
    "정답:\n",
    "'''\n",
    "\n",
    "completion = client.chat.completions. create(model='gpt-3.5-turbo',\n",
    "                                             messages=[{'role':'user', 'content':prompt}],\n",
    "                                             temperature=0\n",
    "                                            )\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "608cc472-4652-4a2c-bbe2-d018928dae36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B. 6\n",
      "\n",
      "우선 주어진 부등식을 그래프로 그려보겠습니다.\n",
      "\n",
      "1. y ≤ x+3\n",
      "이는 y = x+3인 직선을 포함하며, (0,3)을 지나고 기울기가 1인 직선입니다.\n",
      "\n",
      "2. y ≤ -4x+3\n",
      "이는 y = -4x+3인 직선을 포함하며, (0,3)을 지나고 기울기가 -4인 직선입니다.\n",
      "\n",
      "3. y ≥ 0\n",
      "이는 x축 위의 점들을 포함하는 부등식입니다.\n",
      "\n",
      "이 세 부등식을 동시에 만족하는 영역은 위쪽으로 볼록한 영역이며, 이 영역에서 x+y의 최댓값을 구하려면 영역의 가장 위쪽 경계선을 따라 이동하면 됩니다.\n",
      "\n",
      "따라서, y = x+3과 y = -4x+3의 교점을 구하면 x = 0, y = 3이 나오고, 이 때 x+y = 3이 됩니다.\n",
      "\n",
      "따라서, x+y의 최댓값 M은 3이고, 최솟값 m은 0이므로 M-m = 3-0 = 3이 됩니다.\n",
      "\n",
      "그러나 주어진 보기에는 3이 없으므로, 다음으로 최댓값을 만족하는 다른 점을 찾아보겠습니다.\n",
      "\n",
      "y = -4x+3과 y = 0의 교점을 구하면 x = 3/4, y = 0이 나오고, 이 때 x+y = 3/4이 됩니다.\n",
      "\n",
      "따라서, x+y의 최댓값 M은 3이고, 최솟값 m은 0이 아니라 3/4이므로 M-m = 3-3/4 = 9/4 = 2.25가 됩니다.\n",
      "\n",
      "따라서, 주어진 보기 중에서 M-m = 2.25에 가장 가까운 값은 6이므로 정답은 B. 6입니다.\n"
     ]
    }
   ],
   "source": [
    "#영문 prompt 작성\n",
    "\n",
    "prompt = f'''You are an professional in mathematics. \n",
    "Below is given a math question in Korea.\n",
    "You have to think carefully and step by step about the question and choose one of four given answers.\n",
    "Onely one of them is true. and explain it in Korean.\n",
    "After calculating , check the result again.\n",
    "\n",
    "Give reasons step by step and carefully about why you thing your answer is correct.\n",
    "\n",
    "{question}\n",
    "A. {A}\n",
    "B. {B}\n",
    "C. {C}\n",
    "D. {D}\n",
    "정답:\n",
    "'''\n",
    "\n",
    "completion = client.chat.completions. create(model='gpt-3.5-turbo',\n",
    "                                             messages=[{'role':'user', 'content':prompt}],\n",
    "                                             temperature=0\n",
    "                                            )\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15784ef0-e95d-47a7-99eb-86100e769256",
   "metadata": {},
   "source": [
    "### 프롬프트 엔지니어링 특징 정리\n",
    "- 추가 학습이 없음에도 성능 개선의 가능성이 있기 때문에 가성비가 굉장히 좋음\n",
    "- 더 좋은 모델을 사용하면 프롬프트 엔지니어링 없이도 해결할 수 있지만 비용 측면을 무시할 수 없기 때문에 먼저 프롬프트 엔지니어링으로 성능향상을 시도해 보는 것이 좋음(특히 현업에서는 비용문제에 굉장히 민감함)\n",
    "- 단 모델의 알고리즘이 완전히 바뀌어버리면 기존에 사용했던 방법들이 크게 달라질 수 있어서 변동성이 높은편\n",
    "- 프롬프트 엔지니어링으로 해결이 되지 않으면 이후에 배우게 될 RAG와 Fine-tuning으로 성능향상을 시킬수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f26a02-8577-4b86-bf87-96f07f2fdee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe74e1e-f0a3-473a-8597-d41ee66c9177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae0c00-6af2-42f8-9c66-dc38da6e3bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2276d9-f6aa-4a51-8a69-ff63e0ef4a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f92be4-b7f4-458e-bb66-45acee922f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8081fd-7d07-470d-a7d2-f43f15e676fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
